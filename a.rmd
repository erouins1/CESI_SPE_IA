
---
title: "pas mal"
output: "html_document"
date: "2024-09-04"
---

```{r}
library(dplyr)
library(readr)
library(purrr)
knitr::opts_chunk$set(cache = FALSE, autodep = TRUE)

```
```{r}
# List all cv files in the directory Data
csv_files <- fs::dir_ls("./RawData", regexp = "\\.csv$") # nolint: line_length_linter.

# Check if files are detected
if (length(csv_files) == 0) {
  message("No CSV files found in the directory.")
}


# Read all cv files
csv_data <- csv_files %>%
        map_dfr(~ read_csv(.x, col_types = cols()))

if (nrow(csv_data) == 0) {
  print("CSV files are read but no data is present.")
}

# Afficher les premières lignes du nouveau RawData frame pour vérification
head(csv_data)
```
```{r}
data_d <- distinct(csv_data)
# Afficher les premières lignes du nouveau RawData frame pour vérification  
head(data_d)


```

## Première analyse des données
```{r}
df <- data_d
summary(df)
```

---
Nous avons 6 colonnes dans notre jeu de données, dont 5 sont numériques et 1 est catégorielle.

Il existe 10 valeurs différentes dans la colonne Parity, et les répartitions sont très inégales.
Il faudra garder cela en tête lors de l'analyse des résultats du modèle.

Dans un cadre éthique, nous vérifions la répartition de chaque sexe dans notre jeu de données.
---

```{r}
freq_sex <- table(df$Sex)
print(freq_sex)
```

---
Il y a une répartition égale entre les enfants de sexe masculin et féminin, ce qui est un bon signe pour l'analyse des données.

On crée une colonne groupe selon l'ID pour séparer les 2 types d'expérience différentes.
Nous n'avons ensuite plus besoin de l'ID (noté "...1").
---

```{r}
df$Group <- ifelse(df$...1 <= 6000, 1, 2)

if ("...1" %in% names(df)) {
  df <- subset(df, select = -1)
}
head(df)
```

---
On détermine le nombre de valeurs manquantes dans chaque colonne
---

```{r}
na_counts <- colSums(is.na(df))
print(na_counts)
```
---
Au vu du faible nombre de valeurs manquantes par rapport à la taille du jeu de données, nous pouvons les supprimer sans problème. Nous vérifions ensuite qu'elles sont correctement supprimées.
---
```{r}
df <- na.omit(df)
na_counts <- colSums(is.na(df))
print(na_counts)
```
---
Vérifions s'il y a des colonnes contenant des valeurs nulles illogiques.
---
```{r}
zero_counts <- colSums(df == 0)
print(zero_counts)
```
---
Parity est booléen, c'est donc normal d'avoir des valeurs nulles. En revanche, Maternal_weight ne devrait pas avoir de valeur nulle. Nous allons donc supprimer les lignes contenant des valeurs nulles dans cette colonne.
---
```{r}
df <- df %>% filter(Maternal_weight != 0)
zero_counts <- colSums(df == 0)
print(zero_counts)
```
```{r}
boxplot(df$Maternal_age, main = "Maternal age", ylab = "Y-axis Label")
boxplot(df$Maternal_weight, main = "Maternal weight", ylab = "Y-axis Label")
boxplot(df$Maternal_height, main = "Maternal height", ylab = "Y-axis Label")
boxplot(df$Parity, main = "Parity", ylab = "Y-axis Label")
boxplot(df$Gestational_age, main = "Gestational age", ylab = "Y-axis Label")
boxplot(df$Weight, main = "Weight", ylab = "Y-axis Label")
```

---
Concernant la parité, nous remarquons que la plupart des valeurs sont concentrées autour de 0 et 1, avec quelques valeurs aberrantes.
L'écart étant très grand, nous allons supprimer les valeurs aberrantes.
Avec seulement quelques données à la valeur élevée, il y aurait un risque que le modèle ne soit pas capable de généraliser correctement et ne sache pas comment traiter ces valeurs.
---
```{r}
#Deleting entries with Parity greater than or equal to 5
df <- df %>% filter(Parity < 5)
boxplot(df$Parity, main = "Parity", ylab = "Y-axis Label")
```
Les deux dernières boites à moustache, l'une concernant le poids et l'autre l'âge gestationnel, démontrent une grande similitude.
On peut donc supposer une corrélation apparente.

Nous allons maintenant visualiser cette corrélation en utilisant un nuage de points. Cela nous permet de visuellement vérifier la présence de valeur aberrante pour le poids, ce qui est compliqué autrement étant donné que celui-ci dépend de la période de gestation.

Nous tracerons ensuite des nuages de points de l'évolution dans le temps du poids selon chaque variable, prenant en compte la période de gestation.
---
```{r}
library(ggplot2)

ggplot(df, aes(x = Gestational_age, y = Weight)) +
        geom_point() +
        ggtitle("Scatter plot of Weight vs Gestational_age") +
        xlab("Gestational_age") +
        ylab("Weight")
```
```{r}
# Graphe de l'évolution du poids du bébé dans le temps selon l'âge de la mère
ggplot(df, aes(x = Maternal_age, y = Weight, color = Gestational_age)) +
        geom_point() +
        ggtitle("Scatter plot of Weight vs Maternal_age") +
        xlab("Maternal_age") +
        ylab("Weight")

# Graphe de l'évolution du poids du bébé dans le temps selon le poids de la mère
ggplot(df, aes(x = Maternal_weight, y = Weight, color = Gestational_age)) +
        geom_point() +
        ggtitle("Scatter plot of Weight vs Maternal_weight") +
        xlab("Maternal_weight") +
        ylab("Weight")

# Graphe de l'évolution du poids du bébé dans le temps selon la taille de la mère
ggplot(df, aes(x = Maternal_height, y = Weight, color = Gestational_age)) +
        geom_point() +
        ggtitle("Scatter plot of Weight vs Maternal_height") +
        xlab("Maternal_height") +
        ylab("Weight")

# Graphe de l'évolution du poids du bébé dans le temps selon la parité
ggplot(df, aes(x = Parity, y = Weight, color = Gestational_age)) +
        geom_point() +
        ggtitle("Scatter plot of Weight vs Parity") +
        xlab("Parity") +
        ylab("Weight")

# Graphe de l'évolution du poids du bébé dans le temps selon le genre
ggplot(df, aes(x = Sex, y = Weight, color = Gestational_age)) +
        geom_point() +
        ggtitle("Scatter plot of Weight vs Sex") +
        xlab("Sex") +
        ylab("Weight")
```
```{r}
# Matrice de corrélation
correlation_matrix <- cor(df[, c("Maternal_age", "Maternal_weight", "Maternal_height", "Parity", "Gestational_age", "Weight")])
print(correlation_matrix)
```
---
## Hypothèses
La période de gestation est la variable la plus corrélée avec le poids du bébé, ce qui est logique.
Néanmoins, nous avons également une corrélation significative entre le poids du bébé et le poids de la mère.
Pour les autres variables, elles ont un impact sur le poids du bébé, mais il est moindre.
Il n'y a pas de corrélation évidente entre les variables autres que le poids du bébé (hormis entre le poids et la taille de la mère, ce qui est logique et la corrélation n'est pas non plus si élevée).

Notre courbe prédite suivra une tendance générale selon la période de gestation, mais il y aura des variations selon les autres variables, notamment le poids de la mère.

De plus, maintenant que les valeurs aberrantes de parité sont supprimées, nous ne notons plus de valeurs aberrantes dans les autres variables.
---
---
# Préparation des données pour le modèle

## 1- Encodage des variables catégorielles

Il existe une variable catégorielle dans notre jeu de données, le sexe de l'enfant. Nous allons l'encoder en utilisant la méthode de one-hot encoding.
---

```{r}
library(mltools)
library(data.table)

df$Sex <- as.factor(df$Sex)
df$Group <- as.factor(df$Group)
 #df_e <- one_hot(as.data.table(df))
#head(df_e)

```
---
## 2- Normalisation et standardisation

Nous allons normaliser les variables numériques pour les mettre à la même échelle.
La fonction scale centre et réduit les données (moyenne de 0 et écart-type de 1)
---

```{r}

# Transformer Gestational_age de jours en semaines arrondies à l'entier supérieur
df <- df %>%
  mutate(Gestational_age = ceiling(Gestational_age / 7))

# vérifie que le fichier data.csv existe déjà
if (!file.exists("TreatedData/data.csv")) {
  write.csv(df, "TreatedData/data.csv", row.names = FALSE)
}

```

```{R}
# Affichage d'un graphe pour visualiser la corrélation dans le temps ( gestational_age ) entre le poids et l'âge maternel

ggplot(df, aes(x = Gestational_age,y = Weight, color = Maternal_age)) +
  geom_point() +
  ggtitle("Scatter plot of Weight vs Maternal_age and Gestational_age") +
  xlab("Gestational_age") +
  ylab("Weight")

```

```{R}
# Affichage d'un graphe pour visualiser la corrélation dans le temps ( gestational_age ) entre le poids et le poids de la mère

ggplot(df, aes(x = Gestational_age,y = Weight, color = Maternal_weight)) +
  geom_point() +
  ggtitle("Scatter plot of Weight vs Maternal_age and Gestational_age") +
  xlab("Gestational_age") +
  ylab("Weight")

```
```{R}
# Affichage d'un graphe pour visualiser la corrélation dans le temps ( gestational_age ) entre le poids et la taille de la mère

ggplot(df, aes(x = Gestational_age, y = Weight, color = Maternal_height)) +
  geom_point() +
  ggtitle("Scatter plot of Weight vs Maternal_age and Gestational_age") +
  xlab("Maternal_age") +
  ylab("Weight")

```
```{R}
# Affichage d'un graphe pour visualiser la corrélation dans le temps ( gestational_age ) entre le poids et la parité

ggplot(df, aes(x = Gestational_age, y = Weight, color = Parity)) +
  geom_point() +
  ggtitle("Scatter plot of Weight vs Maternal_age and Gestational_age") +
  xlab("Gestational_age") +
  ylab("Weight")

```

```{r}
library(caret)



# Assuming 'df' is your full dataset
set.seed(123) # for reproducibility
splitIndex <- createDataPartition(df$Weight, p = 0.8, list = FALSE)

# Create training and testing datasets
train_set <- df[splitIndex, ]
test_set <- df[-splitIndex, ]

```
```{r}
head(df)
```
```{r}

# Select only numeric columns for scaling
#numeric_columns <- train_set[, sapply(train_set, is.numeric)]

#scaled_numeric_columns  <- scale(numeric_columns, center = TRUE, scale = TRUE)

# Combine scaled numeric columns back with non-numeric columns
#df_s <- cbind(df[, sapply(df, Negate(is.numeric))], as.data.frame(scaled_numeric_columns))


#summary(df_s)



```
```{r}
# Cross-validation setup

train_control <- trainControl(
  method = "cv",
  number = 5
)
```
```{r}
# Fit the linear model on the training dataset
# model_linear <- lm(Weight ~ Maternal_age + Maternal_weight +
#         Maternal_height + Parity + Sex + Gestational_age, data = train_set)

# Fit the model using cross-validation
model_linear <- train(
  log(Weight) ~ Maternal_age + Maternal_weight + Maternal_height + Parity + Sex + Gestational_age,
  data = train_set,
  method = "lm",
  trControl = train_control
)

# Summary of the model
summary(model_linear)

# Evaluate the model on the testing dataset
predictions <- exp(predict(model_linear, newdata = test_set))
test_mse <- mean((test_set$Weight - predictions)^2)
print(test_mse)

# Export the model to a file
saveRDS(model_linear, "Models/linear_model.rds")
```
```{r}
# Modèle polynomial de croissance
model_p_c <- train(
  log(Weight) ~ poly(Gestational_age, 3) + Maternal_age + Maternal_weight + Maternal_height + Parity + Sex,
  data = train_set,
  method = "lm",
  trControl = train_control
)
# Résumé du modèle
summary(model_p_c)

# Test de Kolmogorov-Smirnov avec la distribution normale
ks.test(residuals(model_p_c), "pnorm", mean(residuals(model_p_c)), sd(residuals(model_p_c)))

# Calcul des intervalles de confiance
final_model <- model_p_c$finalModel
model_confidence_intervals <- confint(final_model)
print(model_confidence_intervals)


predictions <- exp(predict(model_p_c, newdata = test_set))
test_mse <- mean((test_set$Weight - predictions)^2)
print(test_mse)

# Export the model to a file
saveRDS(model_p_c, "Models/p_c_model.rds")
```


```{r}
model_poly <- train(
  log(Weight) ~ poly(Maternal_age, 2) + poly(Maternal_weight, 2) +
    poly(Maternal_height, 2) + poly(Parity, 2) +
    poly(Sex, 1) + poly(Gestational_age, 2),
  data = train_set,
  method = "lm",
  trControl = train_control
)


summary(model_poly)

# Evaluate the model on the testing dataset
predictions <- exp(predict(model_poly, newdata = test_set))
test_mse <- mean((test_set$Weight - predictions)^2)
print(test_mse)

# Export the model to a file
saveRDS(model_poly, "Models/polynomial_model.rds")
```
```{r}
# Mixed linear model
library(lme4)

# Cross-validation setup
set.seed(123)
n_folds <- 5
folds <- sample(rep(1:n_folds, length.out = nrow(train_set)))

mse_results <- numeric(n_folds)

for (i in 1:n_folds) {
  test_indices <- which(folds == i)
  train_indices <- setdiff(1:nrow(train_set), test_indices)

  # Subset the data
  training_data <- train_set[train_indices, ]
  testing_data <- train_set[test_indices, ]

  # Fit the model on training data
  model_mixed <- lmer(log(Weight) ~ Maternal_age + Maternal_weight + Maternal_height +
    Parity + Sex + Gestational_age + (1 | Group), data = training_data)

  # Predict and calculate MSE on the testing fold
  predictions <- exp(predict(model_mixed, newdata = testing_data, re.form = NA))  # NA to ignore random effects
  mse_results[i] <- mean((testing_data$Weight - predictions)^2)
}

# Calculate the average MSE over all folds
average_mse <- mean(mse_results)
print(average_mse)

predictions_final <- predict(model_mixed, newdata = test_set)
final_test_mse <- mean((test_set$Weight - predictions_final)^2)
print(final_test_mse)


# Export the mixed model to a file
saveRDS(model_mixed, "Models/mixed_linear_model.rds")
```

```{r}
library(ggplot2)
library(dplyr)

# Create a grid of data to simulate a wider variety of input scenarios
simulated_data <- expand.grid(
        Gestational_age = seq(min(df$Gestational_age), max(df$Gestational_age), by = 0.5),
        Maternal_age = quantile(df$Maternal_age, c(0.25, 0.5, 0.75)),
        Maternal_weight = quantile(df$Maternal_weight, c(0.25, 0.5, 0.75)),
        Maternal_height = quantile(df$Maternal_height, c(0.25, 0.5, 0.75)),
        Parity = unique(df$Parity),
        Sex = factor(levels(df$Sex)),
        Group = factor(levels(df$Group))
)

print(head(simulated_data))


print(levels(train_set$Group))
print(levels(simulated_data$Group))

# Predict weights for the entire grid for both models
# Predict weights for the entire grid for all models
simulated_data$Weight_Linear <- exp(predict(model_linear, newdata = simulated_data))
simulated_data$Weight_Poly <- exp(predict(model_poly, newdata = simulated_data))
simulated_data$Weight_Poly_C <- exp(predict(model_p_c, newdata = simulated_data))
simulated_data$Weight_Mixed <- exp(predict(model_mixed, newdata = simulated_data))


# Function to calculate and plot percentiles
plot_percentiles <- function(data, weight_col, title, color) {
  data %>%
          group_by(Gestational_age) %>%
          summarise(
                  Weight = mean(!!sym(weight_col), na.rm = TRUE),
                  Percentile3 = quantile(!!sym(weight_col), 0.03, na.rm = TRUE),
                  Percentile10 = quantile(!!sym(weight_col), 0.1, na.rm = TRUE),
                  Percentile90 = quantile(!!sym(weight_col), 0.9, na.rm = TRUE),
                  Percentile97 = quantile(!!sym(weight_col), 0.97, na.rm = TRUE),
                  Percentile99 = quantile(!!sym(weight_col), 0.99, na.rm = TRUE)
          ) %>%
          ggplot(aes(x = Gestational_age)) +
          geom_line(aes(y = Weight), color = color, size = 1.2) +
          geom_line(aes(y = Percentile3), color = "blue", linetype = "dashed") +
          geom_line(aes(y = Percentile10), color = "green", linetype = "dashed") +
          geom_line(aes(y = Percentile90), color = "orange", linetype = "dashed") +
          geom_line(aes(y = Percentile97), color = "red", linetype = "dashed") +
          geom_line(aes(y = Percentile99), color = "purple", linetype = "dashed") +
          labs(title = title, y = "Predicted Weight", x = "Gestational Age")
}

# Plot percentiles for both models
p_linear <- plot_percentiles(simulated_data, "Weight_Linear", "Linear Model: Growth Percentiles", "black")
p_poly <- plot_percentiles(simulated_data, "Weight_Poly", "Polynomial Model: Growth Percentiles", "black")
p_poly_c <- plot_percentiles(simulated_data, "Weight_Poly_C", "Polynomial Model: Growth Percentiles", "black")
p_mixed <- plot_percentiles(simulated_data, "Weight_Mixed", "Mixed Linear Model: Growth Percentiles", "black")

```

```{r}
# Predict weights for the entire grid for both models
simulated_data$Weight_Linear <- exp(predict(model_linear, newdata = simulated_data))
simulated_data$Weight_Poly <- exp(predict(model_poly, newdata = simulated_data))
simulated_data$Weight_Poly_C <- exp(predict(model_p_c, newdata = simulated_data))
simulated_data$Weight_Mixed <- exp(predict(model_mixed, newdata = simulated_data))

# Calculate average weights for each gestational age for both models
comparison_data <- simulated_data %>%
        group_by(Gestational_age) %>%
        summarise(
                Average_Weight_Linear = mean(Weight_Linear, na.rm = TRUE),
                Average_Weight_Poly = mean(Weight_Poly, na.rm = TRUE),
                Average_Weight_Poly_C = mean(Weight_Poly_C, na.rm = TRUE),
                Average_Weight_Mixed = mean(Weight_Mixed, na.rm = TRUE)
        )

# Plot graph with curves from all models
p_comparison <- ggplot(comparison_data, aes(x = Gestational_age)) +
        geom_line(aes(y = Average_Weight_Linear, colour = "Linear Model"), size = 1.2) +
        geom_line(aes(y = Average_Weight_Poly, colour = "Polynomial Model"), size = 1.2) +
        geom_line(aes(y = Average_Weight_Poly_C, colour = "Polynomial C Model"), size = 1.2) +
        geom_line(aes(y = Average_Weight_Mixed, colour = "Mixed Linear Model"), size = 1.2) +
        scale_colour_manual(values = c("Linear Model" = "blue", "Polynomial Model" = "red", "Polynomial C Model" = "black", "Mixed Linear Model" = "green")) +
        labs(title = "Comparison of Linear, Polynomials and Mixed Models Predictions",
             y = "Average Predicted Weight", x = "Gestational Age",
             colour = "Model Type")


# Print plots
print(p_linear)
print(p_poly)
print(p_poly_c)
print(p_mixed)
print(p_comparison)
```

```{r}
# Predicted label vs actual label comparison for the linear model
comparison_data_linear <- data.frame(
        Actual = test_set$Weight,
        Predicted = predict(model_linear, newdata = test_set)
)

# Predicted label vs actual label comparison for the polynomial model
comparison_data_poly <- data.frame(
        Actual = test_set$Weight,
        Predicted = predict(model_poly, newdata = test_set)
)

# Predicted label vs actual label comparison for the mixed linear model
comparison_data_mixed <- data.frame(
        Actual = test_set$Weight,
        Predicted = predict(model_mixed, newdata = test_set)
)

# Predicted label vs actual label comparison for the poly-c model
comparison_data_p_c <- data.frame(
        Actual = test_set$Weight,
        Predicted = exp(predict(model_p_c, newdata = test_set))
)

# Plot the comparison
p_comparison_linear <- ggplot(comparison_data_linear, aes(x = Actual, y = Predicted)) +
        geom_point() +
        geom_abline(intercept = 0, slope = 1, color = "red") +
        ggtitle("Linear Model: Predicted vs Actual Weights") +
        xlab("Actual Weight") +
        ylab("Predicted Weight")

p_comparison_poly <- ggplot(comparison_data_poly, aes(x = Actual, y = Predicted)) +
        geom_point() +
        geom_abline(intercept = 0, slope = 1, color = "red") +
        ggtitle("Polynomial Model: Predicted vs Actual Weights") +
        xlab("Actual Weight") +
        ylab("Predicted Weight")

p_comparison_mixed <- ggplot(comparison_data_mixed, aes(x = Actual, y = Predicted)) +
        geom_point() +
        geom_abline(intercept = 0, slope = 1, color = "red") +
        ggtitle("Mixed Linear Model: Predicted vs Actual Weights") +
        xlab("Actual Weight") +
        ylab("Predicted Weight")

p_comparison_p_c <- ggplot(comparison_data_p_c, aes(x = Actual, y = Predicted)) +
        geom_point() +
        geom_abline(intercept = 0, slope = 1, color = "red") +
        ggtitle("Polynomial C Model: Predicted vs Actual Weights") +
        xlab("Actual Weight") +
        ylab("Predicted Weight")

# Print plots
print(p_comparison_linear)
print(p_comparison_poly)
print(p_comparison_mixed)
print(p_comparison_p_c)

```