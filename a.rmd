
---
title: "pas mal"
output: "html_document"
date: "2024-09-04"
---

```{r}
library(dplyr)
library(readr)
library(purrr)
knitr::opts_chunk$set(cache = FALSE, autodep = TRUE)

```
```{r}
# List all cv files in the directory Data
csv_files <- fs::dir_ls("./RawData", regexp = "\\.csv$") # nolint: line_length_linter.

# Check if files are detected
if (length(csv_files) == 0) {
  message("No CSV files found in the directory.")
}


# Read all cv files
csv_data <- csv_files %>%
        map_dfr(~ read_csv(.x, col_types = cols()))

if (nrow(csv_data) == 0) {
  print("CSV files are read but no data is present.")
}

# Afficher les premières lignes du nouveau RawData frame pour vérification
head(csv_data)
```
```{r}
data_d <- distinct(csv_data)
# Afficher les premières lignes du nouveau RawData frame pour vérification  
head(data_d)
# vérifie que le fichier data.csv existe déjà
if (!file.exists("TreatedData/data.csv")) {
  write.csv(data_d, "TreatedData/data.csv", row.names = FALSE)
}

```

## Première analyse des données
```{r}
df <- data_d
summary(df)
```

---
Nous avons 6 colonnes dans notre jeu de données, dont 5 sont numériques et 1 est catégorielle.

Il existe 10 valeurs différentes dans la colonne Parity, et les répartitions sont très inégales.
Il faudra garder cela en tête lors de l'analyse des résultats du modèle.

Dans un cadre éthique, nous vérifions la répartition de chaque sexe dans notre jeu de données.
---

```{r}
freq_sex <- table(df$Sex)
print(freq_sex)
```

---
Il y a une répartition égale entre les enfants de sexe masculin et féminin, ce qui est un bon signe pour l'analyse des données.

On supprime la colonne X qui est inutile
---

```{r}
if ("...1" %in% names(df)) {
  df <- subset(df, select = -1)
}

head(df)
```

---
On détermine le nombre de valeurs manquantes dans chaque colonne
---

```{r}
na_counts <- colSums(is.na(df))
print(na_counts)
```
---
Au vu du faible nombre de valeurs manquantes par rapport à la taille du jeu de données, nous pouvons les supprimer sans problème. Nous vérifions ensuite qu'elles sont correctement supprimées.
---
```{r}
df <- na.omit(df)
na_counts <- colSums(is.na(df))
print(na_counts)
```
---
Vérifions s'il y a des colonnes contenant des valeurs nulles illogiques.
---
```{r}
zero_counts <- colSums(df == 0)
print(zero_counts)
```
---
Parity est booléen, c'est donc normal d'avoir des valeurs nulles. En revanche, Maternal_weight ne devrait pas avoir de valeur nulle. Nous allons donc supprimer les lignes contenant des valeurs nulles dans cette colonne.
---
```{r}
df <- df %>% filter(Maternal_weight != 0)
zero_counts <- colSums(df == 0)
print(zero_counts)
```
```{r}
boxplot(df$Maternal_age, main = "Maternal age", ylab = "Y-axis Label")
boxplot(df$Maternal_weight, main = "Maternal weight", ylab = "Y-axis Label")
boxplot(df$Maternal_height, main = "Maternal height", ylab = "Y-axis Label")
boxplot(df$Parity, main = "Parity", ylab = "Y-axis Label")
boxplot(df$Gestational_age, main = "Gestational age", ylab = "Y-axis Label")
boxplot(df$Weight, main = "Weight", ylab = "Y-axis Label")
```

---
Les deux dernières boites à moustache, l'une concernant le poids et l'autre l'âge gestationnel, démontrent une grande similitude.
On peut donc supposer une corrélation apparente.

Nous allons maintenant visualiser cette corrélation en utilisant un nuage de points. Cela nous permet de visuellement vérifier la présence de valeur aberrante pour le poids, ce qui est compliqué autrement étant donné que celui-ci dépend de la période de gestation.
---
```{r}
library(ggplot2)

ggplot(df, aes(x = Gestational_age, y = Weight)) +
        geom_point() +
        ggtitle("Scatter plot of Weight vs Gestational_age") +
        xlab("Gestational_age") +
        ylab("Weight")
```

---
#Préparation des données pour le modèle

## 1- Encodage des variables catégorielles

Il existe une variable catégorielle dans notre jeu de données, le sexe de l'enfant. Nous allons l'encoder en utilisant la méthode de one-hot encoding.
---

```{r}
library(mltools)
library(data.table)

df$Sex <- as.factor(df$Sex)
 #df_e <- one_hot(as.data.table(df))
#head(df_e)

```
---
## 2- Normalisation et standardisation

Nous allons normaliser les variables numériques pour les mettre à la même échelle.
La fonction scale centre et réduit les données (moyenne de 0 et écart-type de 1)
---
```{r}
library(caret)

# Assuming 'df' is your full dataset
set.seed(123) # for reproducibility
splitIndex <- createDataPartition(df$Weight, p = 0.8, list = FALSE)

# Create training and testing datasets
train_set <- df[splitIndex, ]
test_set <- df[-splitIndex, ]

```
```{r}
head(df)
```
```{r}

# Select only numeric columns for scaling
#numeric_columns <- train_set[, sapply(train_set, is.numeric)]

#scaled_numeric_columns  <- scale(numeric_columns, center = TRUE, scale = TRUE)

# Combine scaled numeric columns back with non-numeric columns
#df_s <- cbind(df[, sapply(df, Negate(is.numeric))], as.data.frame(scaled_numeric_columns))


#summary(df_s)



```
```{r}
# Fit the linear model on the training dataset
model_linear <- lm(Weight ~ Maternal_age + Maternal_weight +
        Maternal_height + Parity + Sex + Gestational_age, data = train_set)

# Summary of the model
summary(model_linear)

# Evaluate the model on the testing dataset
predictions <- predict(model_linear, newdata = test_set)
test_mse <- mean((test_set$Weight - predictions)^2)
print(test_mse)

# Export the model to a file
saveRDS(model_linear, "Models/linear_model.rds")
```

```{r}
model_poly <- lm(Weight ~ poly(Maternal_age, 2) + poly(Maternal_weight, 2) +
        poly(Maternal_height, 2) + poly(Parity, 2) +
        poly(Sex, 1) + poly(Gestational_age, 2), data = train_set)

summary(model_poly)

# Evaluate the model on the testing dataset
predictions <- predict(model_poly, newdata = test_set)
test_mse <- mean((test_set$Weight - predictions)^2)
print(test_mse)

# Export the model to a file
saveRDS(model_poly, "Models/polynomial_model.rds")
```

```{r}
#36 * 7, 39, 70, 152, 1, 2
# Hypothetical values for prediction
new_data <- data.frame(
        Maternal_age = 39,
        Maternal_weight = 70,
        Maternal_height = 152,
        Parity = 2,
        Sex = factor("Male", levels = c("Male", "Female")),  # ensure factor level consistency
        Gestational_age = 36*7
)

# Predict using the linear model
predicted_weight_linear <- predict(model_linear, newdata = new_data)
print(predicted_weight_linear)

# Predict using the polynomial model
predicted_weight_poly <- predict(model_poly, newdata = new_data)
print(predicted_weight_poly)
```
```{r}
# Assume df contains gestational ages ranging from minimum to maximum observed
ages_for_prediction <- data.frame(Gestational_age = seq(min(df$Gestational_age), max(df$Gestational_age), by = 0.5))

# Fill in constant values for other predictors based on hypothetical average or median values
ages_for_prediction$Maternal_age <- median(df$Maternal_age)
ages_for_prediction$Maternal_weight <- median(df$Maternal_weight)
ages_for_prediction$Maternal_height <- median(df$Maternal_height)
ages_for_prediction$Parity <- median(df$Parity)
ages_for_prediction$Sex <- factor("Female", levels = unique(df$Sex))  # Adjust as necessary

# Predict weights using both models
ages_for_prediction$Weight_Linear <- predict(model_linear, newdata = ages_for_prediction)
ages_for_prediction$Weight_Poly <- predict(model_poly, newdata = ages_for_prediction)

# Plotting
library(ggplot2)
ggplot(ages_for_prediction, aes(x = Gestational_age)) +
        geom_line(aes(y = Weight_Linear, colour = "Linear")) +
        geom_line(aes(y = Weight_Poly, colour = "Polynomial")) +
        labs(y = "Predicted Weight", x = "Gestational Age", title = "Predicted Baby Weight by Gestational Age") +
        scale_colour_manual(name = "Model Type", values = c("Linear" = "blue", "Polynomial" = "red"))


```

